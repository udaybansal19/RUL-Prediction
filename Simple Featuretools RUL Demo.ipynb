{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Remaining Useful Life\n",
    "<p style=\"margin:30px\">\n",
    "    <img style=\"display:inline; margin-right:50px\" width=50% src=\"https://www.featuretools.com/wp-content/uploads/2017/12/FeatureLabs-Logo-Tangerine-800.png\" alt=\"Featuretools\" />\n",
    "    <img style=\"display:inline\" width=15% src=\"https://upload.wikimedia.org/wikipedia/commons/e/e5/NASA_logo.svg\" alt=\"NASA\" />\n",
    "</p>\n",
    "\n",
    "The general setup for the problem is a common one: we have a single table of sensor observations over time. Now that collecting information is easier than ever, most industries have already generated *time-series* type problems by the way that they store data. As such, it is crucial to be able to handle data in this form. Thankfully, built-in functionality from [Featuretools](https://www.featuretools.com) handles time varying data well.\n",
    "\n",
    "We'll demonstrate an end-to-end workflow using a [Turbofan Engine Degradation Simulation Data Set](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan) from NASA. This notebook demonstrates a rapid way to predict the Remaining Useful Life (RUL) of an engine using an initial dataframe of time-series data. There are three sections of the notebook:\n",
    "1. [Understand the Data](#Step-1:-Understanding-the-Data)\n",
    "2. [Generate features](#Step-2:-DFS-and-Creating-a-Model)\n",
    "3. [Make predictions with Machine Learning](#Step-3:-Using-the-Model)\n",
    "\n",
    "*To run the notebooks, you need to download the data yourself. Download and unzip the file from [https://ti.arc.nasa.gov/c/13/](https://ti.arc.nasa.gov/c/6/). Then create a 'data' directory and place the files in the 'data' directory.*\n",
    "\n",
    "\n",
    "## Highlights\n",
    "* Quickly make end-to-end workflow using time-series data\n",
    "* Find interesting automatically generated features\n",
    "\n",
    "# Step 1: Understanding the Data\n",
    "Here we load in the train data and give the columns names according to the `description.txt` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import composeml as cp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "import graphviz\n",
    "import datetime\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_data(fileNames, bearingCount):\n",
    "    \n",
    "    compiled_dataset = pd.DataFrame()\n",
    "    \n",
    "    for file in fileNames:\n",
    "        fileData = pd.read_csv(file)\n",
    "        fileData['BearingNumber'] = bearingCount\n",
    "        fileData['TimeStamp'] = pd.to_datetime(fileData['Time'], unit='s')\n",
    "        compiled_dataset = pd.concat([compiled_dataset, fileData])\n",
    "        bearingCount+=1\n",
    "\n",
    "    compiled_dataset['index'] = np.arange(compiled_dataset.shape[0])\n",
    "    \n",
    "    return compiled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Mean</th>\n",
       "      <th>StandardDev</th>\n",
       "      <th>RMS</th>\n",
       "      <th>AbsMean</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>Variance</th>\n",
       "      <th>MaxValue</th>\n",
       "      <th>MinValue</th>\n",
       "      <th>...</th>\n",
       "      <th>SpectralKurtosisKurtosis</th>\n",
       "      <th>SpectralEntropyMean</th>\n",
       "      <th>SpectralEntropyStandardDeviation</th>\n",
       "      <th>SpectralEntropySkewness</th>\n",
       "      <th>SpectralEntropyKurtosis</th>\n",
       "      <th>SquareRootAmplitude</th>\n",
       "      <th>CustomFeature3</th>\n",
       "      <th>BearingNumber</th>\n",
       "      <th>TimeStamp</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.175621</td>\n",
       "      <td>0.175580</td>\n",
       "      <td>0.139071</td>\n",
       "      <td>-0.027739</td>\n",
       "      <td>3.044593</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>0.589792</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>...</td>\n",
       "      <td>6.298457</td>\n",
       "      <td>0.815602</td>\n",
       "      <td>0.031473</td>\n",
       "      <td>-0.900001</td>\n",
       "      <td>3.634679</td>\n",
       "      <td>0.117045</td>\n",
       "      <td>0.666465</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.004930</td>\n",
       "      <td>0.188532</td>\n",
       "      <td>0.188522</td>\n",
       "      <td>0.148198</td>\n",
       "      <td>-0.119761</td>\n",
       "      <td>3.111819</td>\n",
       "      <td>0.035544</td>\n",
       "      <td>0.594009</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>10.231921</td>\n",
       "      <td>0.798574</td>\n",
       "      <td>0.040295</td>\n",
       "      <td>-0.738988</td>\n",
       "      <td>2.737385</td>\n",
       "      <td>0.124100</td>\n",
       "      <td>0.658245</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.003888</td>\n",
       "      <td>0.180922</td>\n",
       "      <td>0.180893</td>\n",
       "      <td>0.144387</td>\n",
       "      <td>-0.028562</td>\n",
       "      <td>2.979709</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>0.603167</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>...</td>\n",
       "      <td>4.208312</td>\n",
       "      <td>0.799238</td>\n",
       "      <td>0.042173</td>\n",
       "      <td>-0.497329</td>\n",
       "      <td>2.874502</td>\n",
       "      <td>0.122366</td>\n",
       "      <td>0.676347</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>-0.001709</td>\n",
       "      <td>0.183055</td>\n",
       "      <td>0.182991</td>\n",
       "      <td>0.144282</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>3.543126</td>\n",
       "      <td>0.033509</td>\n",
       "      <td>0.691722</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>...</td>\n",
       "      <td>7.170531</td>\n",
       "      <td>0.817635</td>\n",
       "      <td>0.035218</td>\n",
       "      <td>-1.344436</td>\n",
       "      <td>6.256718</td>\n",
       "      <td>0.122099</td>\n",
       "      <td>0.667008</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>0.184411</td>\n",
       "      <td>0.184354</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.039858</td>\n",
       "      <td>2.905532</td>\n",
       "      <td>0.034007</td>\n",
       "      <td>0.608446</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>...</td>\n",
       "      <td>5.153746</td>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.034467</td>\n",
       "      <td>-0.414048</td>\n",
       "      <td>2.962452</td>\n",
       "      <td>0.125146</td>\n",
       "      <td>0.678625</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time      Mean  StandardDev       RMS   AbsMean  Skewness  Kurtosis  \\\n",
       "0    10  0.003102     0.175621  0.175580  0.139071 -0.027739  3.044593   \n",
       "1    20  0.004930     0.188532  0.188522  0.148198 -0.119761  3.111819   \n",
       "2    30  0.003888     0.180922  0.180893  0.144387 -0.028562  2.979709   \n",
       "3    40 -0.001709     0.183055  0.182991  0.144282  0.008624  3.543126   \n",
       "4    50 -0.002352     0.184411  0.184354  0.147541  0.039858  2.905532   \n",
       "\n",
       "   Variance  MaxValue  MinValue  ...  SpectralKurtosisKurtosis  \\\n",
       "0  0.030843  0.589792  0.000121  ...                  6.298457   \n",
       "1  0.035544  0.594009  0.000001  ...                 10.231921   \n",
       "2  0.032733  0.603167  0.000100  ...                  4.208312   \n",
       "3  0.033509  0.691722  0.000394  ...                  7.170531   \n",
       "4  0.034007  0.608446  0.000316  ...                  5.153746   \n",
       "\n",
       "   SpectralEntropyMean  SpectralEntropyStandardDeviation  \\\n",
       "0             0.815602                          0.031473   \n",
       "1             0.798574                          0.040295   \n",
       "2             0.799238                          0.042173   \n",
       "3             0.817635                          0.035218   \n",
       "4             0.810007                          0.034467   \n",
       "\n",
       "   SpectralEntropySkewness  SpectralEntropyKurtosis  SquareRootAmplitude  \\\n",
       "0                -0.900001                 3.634679             0.117045   \n",
       "1                -0.738988                 2.737385             0.124100   \n",
       "2                -0.497329                 2.874502             0.122366   \n",
       "3                -1.344436                 6.256718             0.122099   \n",
       "4                -0.414048                 2.962452             0.125146   \n",
       "\n",
       "   CustomFeature3  BearingNumber           TimeStamp  index  \n",
       "0        0.666465              1 1970-01-01 00:00:10      0  \n",
       "1        0.658245              1 1970-01-01 00:00:20      1  \n",
       "2        0.676347              1 1970-01-01 00:00:30      2  \n",
       "3        0.667008              1 1970-01-01 00:00:40      3  \n",
       "4        0.678625              1 1970-01-01 00:00:50      4  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_path = 'data/train_FD004.txt'\n",
    "# data = utils.load_data(data_path)\n",
    "\n",
    "# data.head()\n",
    "\n",
    "learning_dataset_1 = compile_data(['Features/LEARNING SET/Horizontal acceleration Features/Features1_1_Horizontal.csv'\n",
    "                                ,'Features/LEARNING SET/Horizontal acceleration Features/Features1_2_Horizontal.csv']\n",
    "                               , 1)\n",
    "\n",
    "learning_dataset_2 = compile_data(['Features/LEARNING SET/Horizontal acceleration Features/Features2_1_Horizontal.csv'\n",
    "                                ,'Features/LEARNING SET/Horizontal acceleration Features/Features2_2_Horizontal.csv']\n",
    "                               , 3)\n",
    "\n",
    "learning_dataset_3 = compile_data(['Features/LEARNING SET/Horizontal acceleration Features/Features3_1_Horizontal.csv'\n",
    "                                ,'Features/LEARNING SET/Horizontal acceleration Features/Features3_2_Horizontal.csv']\n",
    "                               , 5)\n",
    "\n",
    "# learning_dataset = pd.concat([learning_dataset_1,learning_dataset_2,learning_dataset_3])\n",
    "# learning_dataset['index'] = np.arange(learning_dataset.shape[0])\n",
    "\n",
    "learning_dataset = learning_dataset_1\n",
    "\n",
    "learning_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NASA Run To Failure Dataset\n",
    "In this dataset we have 249 engines (`engine_no`) which are monitored over time (`time_in_cycles`). Each engine had `operational_settings` and `sensor_measurements` recorded for each cycle. The **Remaining Useful Life** (RUL) is the amount of cycles an engine has left before it needs maintenance.\n",
    "What makes this dataset special is that the engines run all the way until failure, giving us precise RUL information for every engine at every point in time.\n",
    "\n",
    "To train a model that will predict RUL, we can can simulate real predictions on by choosing a random point in the life of the engine and only using the data from before that point. We can create features with that restriction easily by using [cutoff_times](https://docs.featuretools.com/automated_feature_engineering/handling_time.html) in Featuretools. To structure the labeling process, we will use [Compose](https://compose.featurelabs.com) which is an open source project for automatically generating labels with cutoff times.\n",
    "\n",
    "### Define Labeling Function\n",
    "To get started, we define the labeling function that will return the RUL given the remaining observations of an engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remaining_useful_life(df):\n",
    "    return len(df) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Label Maker\n",
    "With the labeling function, we create the label maker for our prediction problem. To process the RUL for each engine, we set the `target_entity` to the engine number. By default, the `window_size` is set to the total observation size to contain the remaining observations for each engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = cp.LabelMaker(\n",
    "    target_entity='BearingNumber',\n",
    "    time_index='TimeStamp',\n",
    "    labeling_function=remaining_useful_life,\n",
    ")\n",
    "\n",
    "# lm = cp.LabelMaker(\n",
    "#     target_entity='engine_no',\n",
    "#     time_index='time',\n",
    "#     labeling_function=remaining_useful_life,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Labels\n",
    "Letâ€™s imagine we want to make predictions on turbines that are up and running. Turbines in general donâ€™t fail before 120 cycles, so we will only make labels for engines that reach at least 100 cycles. To do this, the `minimum_data` parameter is set to 100. Using Compose, we can easily tweak this parameter as the requirements of our model changes. By setting `num_examples_per_instance` to one, we limit the search to one example per engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed: 00:00 | Remaining: 00:00 | Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| BearingNumber: 10/10 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BearingNumber</th>\n",
       "      <th>time</th>\n",
       "      <th>remaining_useful_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:50:10</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:58:30</td>\n",
       "      <td>2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 01:06:50</td>\n",
       "      <td>2402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 01:15:10</td>\n",
       "      <td>2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 01:23:30</td>\n",
       "      <td>2302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BearingNumber                time  remaining_useful_life\n",
       "0              1 1970-01-01 00:50:10                   2502\n",
       "1              1 1970-01-01 00:58:30                   2452\n",
       "2              1 1970-01-01 01:06:50                   2402\n",
       "3              1 1970-01-01 01:15:10                   2352\n",
       "4              1 1970-01-01 01:23:30                   2302"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label_times = lm.search(\n",
    "#     data.sort_values('time'),\n",
    "#     num_examples_per_instance=1,\n",
    "#     minimum_data=100,\n",
    "#     verbose=True,\n",
    "# )\n",
    "\n",
    "# label_times.head()\n",
    "\n",
    "label_times = lm.search(\n",
    "    learning_dataset.sort_values('TimeStamp'),\n",
    "    num_examples_per_instance=5,\n",
    "    minimum_data=300,\n",
    "    gap=50,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "label_times.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "Let's walk through a row of the `labels_times` dataframe. In the third row, we have engine number 3. At 00:00 on January 6, the remaining useful life of engine number 3 is 206. Having a dataframe in this format tells Featuretools that the feature vector for engine number 3 should only be calculated with data from before that point in time.\n",
    "\n",
    "To apply Deep Feature Synthesis we need to establish an `EntitySet` structure for our data. The key insight in this step is that we're really interested in our data as collected by `engine`. We can create an `engines` entity by normalizing by the `engine_no` column in the raw data. In the next section, we'll create a feature matrix for the `engines` entity directly rather than the base dataframe of `recordings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_entityset(data):\n",
    "#     es = ft.EntitySet('Dataset')\n",
    "\n",
    "#     es.entity_from_dataframe(\n",
    "#         dataframe=data,\n",
    "#         entity_id='recordings',\n",
    "#         index='index',\n",
    "#         time_index='time',\n",
    "#     )\n",
    "\n",
    "#     es.normalize_entity(\n",
    "#         base_entity_id='recordings',\n",
    "#         new_entity_id='engines',\n",
    "#         index='engine_no',\n",
    "#     )\n",
    "\n",
    "#     es.normalize_entity(\n",
    "#         base_entity_id='recordings',\n",
    "#         new_entity_id='cycles',\n",
    "#         index='time_in_cycles',\n",
    "#     )\n",
    "\n",
    "#     return es\n",
    "\n",
    "def make_entityset(data):\n",
    "    es = ft.EntitySet('Example')\n",
    "    \n",
    "    es.entity_from_dataframe(\n",
    "        dataframe=data,\n",
    "        entity_id='recordings',\n",
    "        index='index',\n",
    "        time_index='TimeStamp',\n",
    "    )\n",
    "\n",
    "    es.normalize_entity(\n",
    "        base_entity_id='recordings',\n",
    "        new_entity_id='Bearings',\n",
    "        index='BearingNumber',\n",
    "    )\n",
    "    \n",
    "#     print(es)\n",
    "#     print(dataset.tail())\n",
    "\n",
    "    es.normalize_entity(\n",
    "        base_entity_id='recordings',\n",
    "        new_entity_id='cycles',\n",
    "        index='Time',\n",
    "    )\n",
    "\n",
    "    return es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entityset: Example\n",
       "  Entities:\n",
       "    recordings [Rows: 3674, Columns: 32]\n",
       "    Bearings [Rows: 2, Columns: 2]\n",
       "    cycles [Rows: 2803, Columns: 2]\n",
       "  Relationships:\n",
       "    recordings.BearingNumber -> Bearings.BearingNumber\n",
       "    recordings.Time -> cycles.Time"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = make_entityset(learning_dataset)\n",
    "es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Visualize EntitySet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\r\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n",
       "<!-- Generated by graphviz version 2.49.2 (20211016.1639)\r\n",
       " -->\r\n",
       "<!-- Title: Example Pages: 1 -->\r\n",
       "<svg width=\"548pt\" height=\"618pt\"\r\n",
       " viewBox=\"0.00 0.00 548.00 618.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 614)\">\r\n",
       "<title>Example</title>\r\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-614 544,-614 544,4 -4,4\"/>\r\n",
       "<!-- recordings -->\r\n",
       "<g id=\"node1\" class=\"node\">\r\n",
       "<title>recordings</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"136,-98.5 136,-609.5 403,-609.5 403,-98.5 136,-98.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"269.5\" y=\"-594.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">recordings (3674 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"136,-586.5 403,-586.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-571.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">index : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-556.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Time : id</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-541.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Mean : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-526.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">StandardDev : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-511.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">RMS : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-496.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AbsMean : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-481.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Skewness : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-466.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Kurtosis : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-451.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Variance : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-436.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MaxValue : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-421.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MinValue : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-406.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Peak2Peak : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-391.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">WaveformIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-376.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">PeakIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-361.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">PulseIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-346.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">MarginIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-331.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SkewnessIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-316.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">KurtosisIndex : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-301.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CustomFeature1 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-286.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CustomFeature2 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-271.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralKurtosisMean : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-256.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralKurtosisStandardDeviation : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-241.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralKurtosisSkewness : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-226.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralKurtosisKurtosis : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-211.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralEntropyMean : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-196.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralEntropyStandardDeviation : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-181.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralEntropySkewness : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-166.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SpectralEntropyKurtosis : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-151.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">SquareRootAmplitude : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-136.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">CustomFeature3 : numeric</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-121.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BearingNumber : id</text>\r\n",
       "<text text-anchor=\"start\" x=\"144\" y=\"-106.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">TimeStamp : datetime_time_index</text>\r\n",
       "</g>\r\n",
       "<!-- Bearings -->\r\n",
       "<g id=\"node2\" class=\"node\">\r\n",
       "<title>Bearings</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-0.5 0,-61.5 261,-61.5 261,-0.5 0,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-46.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Bearings (2 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-38.5 261,-38.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-23.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BearingNumber : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">first_recordings_time : datetime_time_index</text>\r\n",
       "</g>\r\n",
       "<!-- recordings&#45;&gt;Bearings -->\r\n",
       "<g id=\"edge1\" class=\"edge\">\r\n",
       "<title>recordings&#45;&gt;Bearings</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M198.5,-98.32C198.5,-98.32 198.5,-71.73 198.5,-71.73\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"202,-71.73 198.5,-61.73 195,-71.73 202,-71.73\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"154.5\" y=\"-73.82\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">BearingNumber</text>\r\n",
       "</g>\r\n",
       "<!-- cycles -->\r\n",
       "<g id=\"node3\" class=\"node\">\r\n",
       "<title>cycles</title>\r\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"279,-0.5 279,-61.5 540,-61.5 540,-0.5 279,-0.5\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"409.5\" y=\"-46.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">cycles (2803 rows)</text>\r\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"279,-38.5 540,-38.5 \"/>\r\n",
       "<text text-anchor=\"start\" x=\"287\" y=\"-23.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Time : index</text>\r\n",
       "<text text-anchor=\"start\" x=\"287\" y=\"-8.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">first_recordings_time : datetime_time_index</text>\r\n",
       "</g>\r\n",
       "<!-- recordings&#45;&gt;cycles -->\r\n",
       "<g id=\"edge2\" class=\"edge\">\r\n",
       "<title>recordings&#45;&gt;cycles</title>\r\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M341,-98.32C341,-98.32 341,-71.73 341,-71.73\"/>\r\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"344.5,-71.73 341,-61.73 337.5,-71.73 344.5,-71.73\"/>\r\n",
       "<text text-anchor=\"middle\" x=\"326.5\" y=\"-73.82\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Time</text>\r\n",
       "</g>\r\n",
       "</g>\r\n",
       "</svg>\r\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x258b2b32eb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: DFS and Creating a Model\n",
    "With the work from the last section in hand, we can quickly build features using Deep Feature Synthesis (DFS). The function `ft.dfs` takes an `EntitySet` and stacks primitives like `Max`, `Min` and `Last` exhaustively across entities. Feel free to try the next step with a different primitive set to see how the results differ!\n",
    "\n",
    "We build features only using data up to and including the cutoff time of each label. This is done by setting the `cutoff_time` parameter to the label times we generated previously. Notice that the output of Compose integrates easily with Featuretools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built 340 features\n",
      "Elapsed: 00:06 | Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n"
     ]
    }
   ],
   "source": [
    "fm, features = ft.dfs(\n",
    "    entityset=es,\n",
    "    target_entity='Bearings',\n",
    "    agg_primitives=['last', 'max', 'min'],\n",
    "    trans_primitives=[],\n",
    "    cutoff_time=label_times,\n",
    "    max_depth=3,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fm.to_csv('simple_fm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Baselines\n",
    "Before we use that feature matrix to make predictions, we should check how well guessing does on this dataset. We can use a `train_test_split` from scikit-learn to split our training data once and for all. Then, we'll check the following baselines:\n",
    "1. Always predict the median value of `y_train`\n",
    "2. Always predict the RUL as if every engine has the median lifespan in `X_train`\n",
    "\n",
    "We'll check those predictions by finding the mean of the absolute value of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline by median label: Mean Abs Error = 1221.33\n"
     ]
    }
   ],
   "source": [
    "# fm = pd.read_csv('simple_fm.csv', index_col='engine_no')\n",
    "# X = fm.copy().fillna(0)\n",
    "# y = X.pop('remaining_useful_life')\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "\n",
    "# medianpredict1 = [np.median(y_train) for _ in y_test]\n",
    "# mae = mean_absolute_error(medianpredict1, y_test)\n",
    "# print('Baseline by median label: Mean Abs Error = {:.2f}'.format(mae))\n",
    "\n",
    "fm = pd.read_csv('simple_fm.csv', index_col='BearingNumber')\n",
    "X = fm.copy().fillna(0)\n",
    "y = X.pop('remaining_useful_life')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "medianpredict1 = [np.median(y_train) for _ in y_test]\n",
    "mae = mean_absolute_error(medianpredict1, y_test)\n",
    "print('Baseline by median label: Mean Abs Error = {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline by median life: Mean Abs Error = 966.00\n"
     ]
    }
   ],
   "source": [
    "# from_train = es['recordings'].df['engine_no'].isin(y_train.index)\n",
    "# recordings_from_train = es['recordings'].df[from_train]\n",
    "# engines = recordings_from_train.groupby(['engine_no'])\n",
    "# median_life = np.median(engines.apply(lambda df: df.shape[0]))\n",
    "\n",
    "# from_test = es['recordings'].df['engine_no'].isin(y_test.index)\n",
    "# recordings_from_test = es['recordings'].df[from_test]\n",
    "# engines = recordings_from_test.groupby(['engine_no'])\n",
    "# life_in_test = engines.apply(lambda df: df.shape[0]) - y_test\n",
    "\n",
    "# medianpredict2 = median_life - life_in_test\n",
    "# medianpredict2 = medianpredict2.apply(lambda row: max(row, 0))\n",
    "# mae = mean_absolute_error(medianpredict2, y_test)\n",
    "# print('Baseline by median life: Mean Abs Error = {:.2f}'.format(mae))\n",
    "\n",
    "from_train = es['recordings'].df['BearingNumber'].isin(y_train.index)\n",
    "recordings_from_train = es['recordings'].df[from_train]\n",
    "Bearings = recordings_from_train.groupby(['BearingNumber'])\n",
    "median_life = np.median(Bearings.apply(lambda df: df.shape[0]))\n",
    "\n",
    "from_test = es['recordings'].df['BearingNumber'].isin(y_test.index)\n",
    "recordings_from_test = es['recordings'].df[from_test]\n",
    "Bearings = recordings_from_test.groupby(['BearingNumber'])\n",
    "life_in_test = Bearings.apply(lambda df: df.shape[0]) - y_test\n",
    "\n",
    "medianpredict2 = median_life - life_in_test\n",
    "medianpredict2 = medianpredict2.apply(lambda row: max(row, 0))\n",
    "mae = mean_absolute_error(medianpredict2, y_test)\n",
    "print('Baseline by median life: Mean Abs Error = {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Using the Model\n",
    "Now, we can use our created features to fit a `RandomForestRegressor` to our data and see if we can improve on the previous scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 615.38 2232.44  671.52]\n",
      "-----\n",
      "BearingNumber\n",
      "2     470\n",
      "1    2402\n",
      "2     570\n",
      "Name: remaining_useful_life, dtype: int64\n",
      "Mean Abs Error: 138.82\n",
      "1: MIN(recordings.MaxValue) [0.060]\n",
      "2: MAX(recordings.KurtosisIndex) [0.050]\n",
      "3: LAST(recordings.index) [0.040]\n",
      "4: MIN(recordings.AbsMean) [0.040]\n",
      "5: MIN(recordings.SpectralEntropySkewness) [0.040]\n",
      "6: MIN(recordings.StandardDev) [0.040]\n",
      "7: MIN(recordings.SpectralKurtosisMean) [0.040]\n",
      "8: MIN(recordings.KurtosisIndex) [0.030]\n",
      "9: MIN(recordings.SpectralEntropyStandardDeviation) [0.030]\n",
      "10: MIN(recordings.SquareRootAmplitude) [0.030]\n",
      "-----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg = RandomForestRegressor(n_estimators=100)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "preds = reg.predict(X_test)\n",
    "print(preds)\n",
    "print(\"-----\")\n",
    "print(y_test)\n",
    "scores = mean_absolute_error(preds, y_test)\n",
    "print('Mean Abs Error: {:.2f}'.format(scores))\n",
    "\n",
    "high_imp_feats = utils.feature_importances(X, reg, feats=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can apply the exact same transformations (including DFS) to our test data. For this particular case, the real answer isn't in the data so we don't need to worry about cutoff times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entityset: Example\n",
      "  Entities:\n",
      "    recordings [Rows: 9047, Columns: 32]\n",
      "    Bearings [Rows: 5, Columns: 2]\n",
      "    cycles [Rows: 2302, Columns: 2]\n",
      "  Relationships:\n",
      "    recordings.BearingNumber -> Bearings.BearingNumber\n",
      "    recordings.Time -> cycles.Time\n",
      "Elapsed: 00:03 | Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAST(recordings.AbsMean)</th>\n",
       "      <th>LAST(recordings.CustomFeature1)</th>\n",
       "      <th>LAST(recordings.CustomFeature2)</th>\n",
       "      <th>LAST(recordings.CustomFeature3)</th>\n",
       "      <th>LAST(recordings.Kurtosis)</th>\n",
       "      <th>LAST(recordings.KurtosisIndex)</th>\n",
       "      <th>LAST(recordings.MarginIndex)</th>\n",
       "      <th>LAST(recordings.MaxValue)</th>\n",
       "      <th>LAST(recordings.Mean)</th>\n",
       "      <th>LAST(recordings.MinValue)</th>\n",
       "      <th>...</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralEntropySkewness))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralEntropyStandardDeviation))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralKurtosisKurtosis))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralKurtosisMean))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralKurtosisSkewness))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SpectralKurtosisStandardDeviation))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.SquareRootAmplitude))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.StandardDev))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.Variance))</th>\n",
       "      <th>MIN(recordings.cycles.MIN(recordings.WaveformIndex))</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BearingNumber</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.631106</td>\n",
       "      <td>1.995968</td>\n",
       "      <td>0.794584</td>\n",
       "      <td>0.670827</td>\n",
       "      <td>3.227265</td>\n",
       "      <td>8.079792</td>\n",
       "      <td>4.076633</td>\n",
       "      <td>3.240043</td>\n",
       "      <td>0.013241</td>\n",
       "      <td>0.002406</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652358</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1.918988</td>\n",
       "      <td>-0.079697</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.278084</td>\n",
       "      <td>0.10712</td>\n",
       "      <td>0.157737</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.756441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.230201</td>\n",
       "      <td>1.338354</td>\n",
       "      <td>2.023876</td>\n",
       "      <td>0.449702</td>\n",
       "      <td>10.812178</td>\n",
       "      <td>0.642421</td>\n",
       "      <td>6.862637</td>\n",
       "      <td>13.894558</td>\n",
       "      <td>-0.000186</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.526124</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>2.042639</td>\n",
       "      <td>-0.079697</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.278084</td>\n",
       "      <td>0.10712</td>\n",
       "      <td>0.157737</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.756441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.140864</td>\n",
       "      <td>8.899207</td>\n",
       "      <td>0.178686</td>\n",
       "      <td>0.673245</td>\n",
       "      <td>3.219120</td>\n",
       "      <td>3310.736811</td>\n",
       "      <td>4.175153</td>\n",
       "      <td>0.741641</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652358</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1.918988</td>\n",
       "      <td>-0.079697</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.263439</td>\n",
       "      <td>0.10712</td>\n",
       "      <td>0.157737</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.756441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.179991</td>\n",
       "      <td>7.535124</td>\n",
       "      <td>0.244475</td>\n",
       "      <td>0.604649</td>\n",
       "      <td>7.128768</td>\n",
       "      <td>2007.461146</td>\n",
       "      <td>6.855773</td>\n",
       "      <td>1.674825</td>\n",
       "      <td>-0.011610</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652358</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>1.918988</td>\n",
       "      <td>-0.079697</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.263439</td>\n",
       "      <td>0.10712</td>\n",
       "      <td>0.157737</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.756441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.174733</td>\n",
       "      <td>7.395109</td>\n",
       "      <td>0.226147</td>\n",
       "      <td>0.648133</td>\n",
       "      <td>4.397801</td>\n",
       "      <td>1692.245807</td>\n",
       "      <td>4.801811</td>\n",
       "      <td>1.085044</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.652358</td>\n",
       "      <td>0.014819</td>\n",
       "      <td>2.042639</td>\n",
       "      <td>-0.079697</td>\n",
       "      <td>0.179296</td>\n",
       "      <td>0.278084</td>\n",
       "      <td>0.10712</td>\n",
       "      <td>0.157737</td>\n",
       "      <td>0.024881</td>\n",
       "      <td>0.756441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 340 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               LAST(recordings.AbsMean)  LAST(recordings.CustomFeature1)  \\\n",
       "BearingNumber                                                              \n",
       "7                              0.631106                         1.995968   \n",
       "8                              1.230201                         1.338354   \n",
       "9                              0.140864                         8.899207   \n",
       "10                             0.179991                         7.535124   \n",
       "11                             0.174733                         7.395109   \n",
       "\n",
       "               LAST(recordings.CustomFeature2)  \\\n",
       "BearingNumber                                    \n",
       "7                                     0.794584   \n",
       "8                                     2.023876   \n",
       "9                                     0.178686   \n",
       "10                                    0.244475   \n",
       "11                                    0.226147   \n",
       "\n",
       "               LAST(recordings.CustomFeature3)  LAST(recordings.Kurtosis)  \\\n",
       "BearingNumber                                                               \n",
       "7                                     0.670827                   3.227265   \n",
       "8                                     0.449702                  10.812178   \n",
       "9                                     0.673245                   3.219120   \n",
       "10                                    0.604649                   7.128768   \n",
       "11                                    0.648133                   4.397801   \n",
       "\n",
       "               LAST(recordings.KurtosisIndex)  LAST(recordings.MarginIndex)  \\\n",
       "BearingNumber                                                                 \n",
       "7                                    8.079792                      4.076633   \n",
       "8                                    0.642421                      6.862637   \n",
       "9                                 3310.736811                      4.175153   \n",
       "10                                2007.461146                      6.855773   \n",
       "11                                1692.245807                      4.801811   \n",
       "\n",
       "               LAST(recordings.MaxValue)  LAST(recordings.Mean)  \\\n",
       "BearingNumber                                                     \n",
       "7                               3.240043               0.013241   \n",
       "8                              13.894558              -0.000186   \n",
       "9                               0.741641               0.019884   \n",
       "10                              1.674825              -0.011610   \n",
       "11                              1.085044               0.011041   \n",
       "\n",
       "               LAST(recordings.MinValue)  ...  \\\n",
       "BearingNumber                             ...   \n",
       "7                               0.002406  ...   \n",
       "8                               0.000165  ...   \n",
       "9                               0.000026  ...   \n",
       "10                              0.000021  ...   \n",
       "11                              0.000286  ...   \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralEntropySkewness))  \\\n",
       "BearingNumber                                                                   \n",
       "7                                                      -2.652358                \n",
       "8                                                      -2.526124                \n",
       "9                                                      -2.652358                \n",
       "10                                                     -2.652358                \n",
       "11                                                     -2.652358                \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralEntropyStandardDeviation))  \\\n",
       "BearingNumber                                                                            \n",
       "7                                                       0.014819                         \n",
       "8                                                       0.014819                         \n",
       "9                                                       0.014819                         \n",
       "10                                                      0.014819                         \n",
       "11                                                      0.014819                         \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralKurtosisKurtosis))  \\\n",
       "BearingNumber                                                                    \n",
       "7                                                       1.918988                 \n",
       "8                                                       2.042639                 \n",
       "9                                                       1.918988                 \n",
       "10                                                      1.918988                 \n",
       "11                                                      2.042639                 \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralKurtosisMean))  \\\n",
       "BearingNumber                                                                \n",
       "7                                                      -0.079697             \n",
       "8                                                      -0.079697             \n",
       "9                                                      -0.079697             \n",
       "10                                                     -0.079697             \n",
       "11                                                     -0.079697             \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralKurtosisSkewness))  \\\n",
       "BearingNumber                                                                    \n",
       "7                                                       0.179296                 \n",
       "8                                                       0.179296                 \n",
       "9                                                       0.179296                 \n",
       "10                                                      0.179296                 \n",
       "11                                                      0.179296                 \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SpectralKurtosisStandardDeviation))  \\\n",
       "BearingNumber                                                                             \n",
       "7                                                       0.278084                          \n",
       "8                                                       0.278084                          \n",
       "9                                                       0.263439                          \n",
       "10                                                      0.263439                          \n",
       "11                                                      0.278084                          \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.SquareRootAmplitude))  \\\n",
       "BearingNumber                                                               \n",
       "7                                                        0.10712            \n",
       "8                                                        0.10712            \n",
       "9                                                        0.10712            \n",
       "10                                                       0.10712            \n",
       "11                                                       0.10712            \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.StandardDev))  \\\n",
       "BearingNumber                                                       \n",
       "7                                                       0.157737    \n",
       "8                                                       0.157737    \n",
       "9                                                       0.157737    \n",
       "10                                                      0.157737    \n",
       "11                                                      0.157737    \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.Variance))  \\\n",
       "BearingNumber                                                    \n",
       "7                                                     0.024881   \n",
       "8                                                     0.024881   \n",
       "9                                                     0.024881   \n",
       "10                                                    0.024881   \n",
       "11                                                    0.024881   \n",
       "\n",
       "               MIN(recordings.cycles.MIN(recordings.WaveformIndex))  \n",
       "BearingNumber                                                        \n",
       "7                                                       0.756441     \n",
       "8                                                       0.756441     \n",
       "9                                                       0.756441     \n",
       "10                                                      0.756441     \n",
       "11                                                      0.756441     \n",
       "\n",
       "[5 rows x 340 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data2 = utils.load_data('data/test_FD004.txt')\n",
    "# es2 = make_entityset(data2)\n",
    "# print(data2)\n",
    "\n",
    "# path = 'Features/TEST SET/Horizontal acceleration Features/'\n",
    "# dataset1_3 = pd.read_csv(path+'Features1_3_Horizontal.csv')\n",
    "\n",
    "# dataset1_3['BearingNumber'] = 3\n",
    "# dataset1_3['TimeStamp'] = pd.to_datetime(dataset1_3['Time'], unit='s')\n",
    "# dataset1_3['index'] = np.arange(dataset1_3.shape[0])\n",
    "\n",
    "test_dataset = compile_data(['Features/TEST SET/Horizontal acceleration Features/Features1_3_Horizontal.csv'\n",
    "                       ,'Features/TEST SET/Horizontal acceleration Features/Features1_4_Horizontal.csv'\n",
    "                       ,'Features/TEST SET/Horizontal acceleration Features/Features1_5_Horizontal.csv'\n",
    "                       ,'Features/TEST SET/Horizontal acceleration Features/Features1_6_Horizontal.csv'\n",
    "                       ,'Features/TEST SET/Horizontal acceleration Features/Features1_7_Horizontal.csv']\n",
    "                           ,7)\n",
    "es2 = make_entityset(test_dataset)\n",
    "print(es2)\n",
    "\n",
    "fm2 = ft.calculate_feature_matrix(\n",
    "    entityset=es2,\n",
    "    features=features,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "fm2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1154.84 1519.1  1236.62  904.18 1243.12]\n",
      "Mean Abs Error: 2602.27\n",
      "Baseline by median label: Mean Abs Error = 2438.60\n",
      "Baseline by median life: Mean Abs Error = 3271.80\n"
     ]
    }
   ],
   "source": [
    "# X = fm2.copy().fillna(0)\n",
    "\n",
    "# preds2 = reg.predict(X)\n",
    "# mae = mean_absolute_error(preds2, y)\n",
    "# print('Mean Abs Error: {:.2f}'.format(mae))\n",
    "\n",
    "# medianpredict1 = [np.median(y_train) for _ in preds2]\n",
    "# mae = mean_absolute_error(medianpredict1, y)\n",
    "# print('Baseline by median label: Mean Abs Error = {:.2f}'.format(mae))\n",
    "\n",
    "# engines = es2['recordings'].df.groupby(['engine_no'])\n",
    "# medianpredict2 = median_life - engines.apply(lambda df: df.shape[0])\n",
    "# medianpredict2 = medianpredict2.apply(lambda row: max(row, 0))\n",
    "# mae = mean_absolute_error(medianpredict2, y)\n",
    "# print('Baseline by median life: Mean Abs Error = {:.2f}'.format(mae))\n",
    "\n",
    "\n",
    "X = fm2.copy().fillna(0)\n",
    "\n",
    "# y = pd.read_csv(\n",
    "#     'data/RUL_FD004.txt',\n",
    "#     sep=' ',\n",
    "#     header=None,\n",
    "#     names=['remaining_useful_life'],\n",
    "#     index_col=False,\n",
    "# )\n",
    "# print(y)\n",
    "\n",
    "y = pd.DataFrame(data = {'remaining_useful_life': [5730, 339, 1610, 1460, 7570]})\n",
    "\n",
    "preds2 = reg.predict(X)\n",
    "print(preds2)\n",
    "mae = mean_absolute_error(preds2, y)\n",
    "print('Mean Abs Error: {:.2f}'.format(mae))\n",
    "\n",
    "medianpredict1 = [np.median(y_train) for _ in preds2]\n",
    "mae = mean_absolute_error(medianpredict1, y)\n",
    "print('Baseline by median label: Mean Abs Error = {:.2f}'.format(mae))\n",
    "\n",
    "engines = es2['recordings'].df.groupby(['BearingNumber'])\n",
    "medianpredict2 = median_life - engines.apply(lambda df: df.shape[0])\n",
    "medianpredict2 = medianpredict2.apply(lambda row: max(row, 0))\n",
    "mae = mean_absolute_error(medianpredict2, y)\n",
    "print('Baseline by median life: Mean Abs Error = {:.2f}'.format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the simple version of a more advanced notebook that can be found in the [second](Advanced%20Featuretools%20RUL.ipynb) notebook. That notebook will show how to use a novel entityset structure, custom primitives, and automated hyperparameter tuning to improve the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save output files\n",
    "os.makedirs('output', exist_ok=True)\n",
    "fm.to_csv('output/simple_train_feature_matrix.csv')\n",
    "label_times.to_csv('output/simple_train_label_times.csv')\n",
    "fm2.to_csv('output/simple_test_feature_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <img src=\"https://www.featurelabs.com/wp-content/uploads/2017/12/logo.png\" alt=\"Featuretools\" />\n",
    "</p>\n",
    "\n",
    "Featuretools was created by the developers at [Feature Labs](https://www.featurelabs.com/). If building impactful data science pipelines is important to you or your business, please [get in touch](https://www.featurelabs.com/contact)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "91383ca01c745ff4f6ec61074eff8198c75652caf775a5c5ee2312577bd67511"
  },
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
